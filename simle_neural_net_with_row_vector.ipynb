{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\g√°bor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape([1, 2, 3, 4, 5], (5, 1))\n",
    "Y_train = np.reshape([5, 7, 11, 14, 17], (5, 1))\n",
    "X = tf.placeholder(dtype=tf.float32, name='X', shape=(5, 1))\n",
    "W = tf.Variable(initial_value=tf.random_uniform([1], minval=-10.0, maxval=10.0), name='W')\n",
    "B = tf.Variable(initial_value=tf.random_uniform([1], minval=-10.0, maxval=10.0), name='B')\n",
    "Y = X * W + B\n",
    "Y_ = tf.placeholder(dtype=tf.float32, name='Y_', shape=(5, 1))\n",
    "Loss = tf.reduce_sum((Y-Y_) ** 2)\n",
    "training_op = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1759.83251953125, Weight: [6.1821303], Bias: [-5.9469624]\n",
      "Loss: 111.88499450683594, Weight: [5.0258756], Bias: [-6.1269054]\n",
      "Loss: 54.88912582397461, Weight: [5.195484], Bias: [-5.9419775]\n",
      "Loss: 51.28672409057617, Weight: [5.123045], Bias: [-5.826425]\n",
      "Loss: 49.531002044677734, Weight: [5.095623], Bias: [-5.700696]\n",
      "Loss: 47.891998291015625, Weight: [5.0606465], Bias: [-5.5793133]\n",
      "Loss: 46.30986404418945, Weight: [5.0277295], Bias: [-5.459576]\n",
      "Loss: 44.780845642089844, Weight: [4.9951], Bias: [-5.3419375]\n",
      "Loss: 43.3030891418457, Weight: [4.9630713], Bias: [-5.2262735]\n",
      "Loss: 41.8748779296875, Weight: [4.931575], Bias: [-5.1125674]\n",
      "Loss: 40.494529724121094, Weight: [4.900613], Bias: [-5.000783]\n",
      "Loss: 39.160457611083984, Weight: [4.8701735], Bias: [-4.8908887]\n",
      "Loss: 37.87112808227539, Weight: [4.840249], Bias: [-4.7828517]\n",
      "Loss: 36.62499237060547, Weight: [4.8108306], Bias: [-4.676641]\n",
      "Loss: 35.420654296875, Weight: [4.7819095], Bias: [-4.572226]\n",
      "Loss: 34.25668716430664, Weight: [4.7534766], Bias: [-4.4695764]\n",
      "Loss: 33.131736755371094, Weight: [4.725525], Bias: [-4.368662]\n",
      "Loss: 32.044498443603516, Weight: [4.698046], Bias: [-4.269453]\n",
      "Loss: 30.993703842163086, Weight: [4.6710315], Bias: [-4.1719217]\n",
      "Loss: 29.978147506713867, Weight: [4.6444736], Bias: [-4.076039]\n",
      "Loss: 28.99663543701172, Weight: [4.6183643], Bias: [-3.981777]\n",
      "Loss: 28.048019409179688, Weight: [4.5926967], Bias: [-3.8891087]\n",
      "Loss: 27.131210327148438, Weight: [4.567463], Bias: [-3.7980068]\n",
      "Loss: 26.245136260986328, Weight: [4.542656], Bias: [-3.708445]\n",
      "Loss: 25.388765335083008, Weight: [4.5182676], Bias: [-3.6203973]\n",
      "Loss: 24.561105728149414, Weight: [4.4942923], Bias: [-3.5338378]\n",
      "Loss: 23.761184692382812, Weight: [4.470722], Bias: [-3.4487417]\n",
      "Loss: 22.988082885742188, Weight: [4.4475503], Bias: [-3.3650842]\n",
      "Loss: 22.24090003967285, Weight: [4.4247704], Bias: [-3.282841]\n",
      "Loss: 21.518766403198242, Weight: [4.402375], Bias: [-3.201988]\n",
      "Loss: 20.82084083557129, Weight: [4.380359], Bias: [-3.1225016]\n",
      "Loss: 20.146316528320312, Weight: [4.3587146], Bias: [-3.0443592]\n",
      "Loss: 19.494400024414062, Weight: [4.337436], Bias: [-2.9675376]\n",
      "Loss: 18.864343643188477, Weight: [4.316518], Bias: [-2.8920147]\n",
      "Loss: 18.255393981933594, Weight: [4.295953], Bias: [-2.8177686]\n",
      "Loss: 17.666873931884766, Weight: [4.2757354], Bias: [-2.7447774]\n",
      "Loss: 17.09808349609375, Weight: [4.25586], Bias: [-2.6730204]\n",
      "Loss: 16.54834747314453, Weight: [4.23632], Bias: [-2.6024764]\n",
      "Loss: 16.017059326171875, Weight: [4.2171106], Bias: [-2.5331247]\n",
      "Loss: 15.503565788269043, Weight: [4.1982265], Bias: [-2.4649453]\n",
      "Loss: 15.007299423217773, Weight: [4.179661], Bias: [-2.3979187]\n",
      "Loss: 14.527660369873047, Weight: [4.1614094], Bias: [-2.332025]\n",
      "Loss: 14.064102172851562, Weight: [4.1434665], Bias: [-2.2672453]\n",
      "Loss: 13.616089820861816, Weight: [4.125827], Bias: [-2.2035608]\n",
      "Loss: 13.183094024658203, Weight: [4.108485], Bias: [-2.1409528]\n",
      "Loss: 12.76461124420166, Weight: [4.0914373], Bias: [-2.0794032]\n",
      "Loss: 12.360158920288086, Weight: [4.074677], Bias: [-2.0188942]\n",
      "Loss: 11.969261169433594, Weight: [4.0582004], Bias: [-1.9594079]\n",
      "Loss: 11.591475486755371, Weight: [4.042002], Bias: [-1.9009273]\n",
      "Loss: 11.226350784301758, Weight: [4.0260777], Bias: [-1.8434353]\n",
      "Loss: 10.873464584350586, Weight: [4.0104227], Bias: [-1.7869151]\n",
      "Loss: 10.532410621643066, Weight: [3.9950323], Bias: [-1.7313504]\n",
      "Loss: 10.202797889709473, Weight: [3.9799018], Bias: [-1.6767251]\n",
      "Loss: 9.884224891662598, Weight: [3.9650273], Bias: [-1.6230232]\n",
      "Loss: 9.576327323913574, Weight: [3.9504044], Bias: [-1.570229]\n",
      "Loss: 9.278762817382812, Weight: [3.9360282], Bias: [-1.5183275]\n",
      "Loss: 8.991170883178711, Weight: [3.9218955], Bias: [-1.4673032]\n",
      "Loss: 8.713223457336426, Weight: [3.9080014], Bias: [-1.4171416]\n",
      "Loss: 8.444583892822266, Weight: [3.8943424], Bias: [-1.3678279]\n",
      "Loss: 8.184956550598145, Weight: [3.8809142], Bias: [-1.3193479]\n",
      "Loss: 7.934034824371338, Weight: [3.8677127], Bias: [-1.2716874]\n",
      "Loss: 7.69152307510376, Weight: [3.854735], Bias: [-1.2248325]\n",
      "Loss: 7.457136631011963, Weight: [3.8419764], Bias: [-1.1787697]\n",
      "Loss: 7.230613708496094, Weight: [3.8294332], Bias: [-1.1334857]\n",
      "Loss: 7.011679649353027, Weight: [3.8171024], Bias: [-1.0889671]\n",
      "Loss: 6.80009126663208, Weight: [3.8049798], Bias: [-1.0452011]\n",
      "Loss: 6.595591068267822, Weight: [3.7930622], Bias: [-1.0021749]\n",
      "Loss: 6.397947788238525, Weight: [3.781346], Bias: [-0.95987606]\n",
      "Loss: 6.2069292068481445, Weight: [3.7698283], Bias: [-0.9182923]\n",
      "Loss: 6.0223164558410645, Weight: [3.7585049], Bias: [-0.87741154]\n",
      "Loss: 5.843894004821777, Weight: [3.7473729], Bias: [-0.83722186]\n",
      "Loss: 5.671449661254883, Weight: [3.7364292], Bias: [-0.79771155]\n",
      "Loss: 5.504785537719727, Weight: [3.7256706], Bias: [-0.7588692]\n",
      "Loss: 5.34371280670166, Weight: [3.7150936], Bias: [-0.72068346]\n",
      "Loss: 5.1880364418029785, Weight: [3.7046957], Bias: [-0.6831432]\n",
      "Loss: 5.037581443786621, Weight: [3.6944735], Bias: [-0.6462376]\n",
      "Loss: 4.8921685218811035, Weight: [3.684424], Bias: [-0.6099559]\n",
      "Loss: 4.7516279220581055, Weight: [3.6745446], Bias: [-0.5742875]\n",
      "Loss: 4.615804195404053, Weight: [3.6648319], Bias: [-0.5392221]\n",
      "Loss: 4.484531402587891, Weight: [3.6552835], Bias: [-0.5047495]\n",
      "Loss: 4.357659339904785, Weight: [3.6458964], Bias: [-0.4708596]\n",
      "Loss: 4.235042572021484, Weight: [3.6366682], Bias: [-0.43754256]\n",
      "Loss: 4.116535186767578, Weight: [3.627596], Bias: [-0.4047888]\n",
      "Loss: 4.001997470855713, Weight: [3.6186771], Bias: [-0.37258866]\n",
      "Loss: 3.8913018703460693, Weight: [3.609909], Bias: [-0.3409329]\n",
      "Loss: 3.7843170166015625, Weight: [3.601289], Bias: [-0.30981234]\n",
      "Loss: 3.6809186935424805, Weight: [3.592815], Bias: [-0.2792178]\n",
      "Loss: 3.580986976623535, Weight: [3.5844839], Bias: [-0.2491405]\n",
      "Loss: 3.484405994415283, Weight: [3.5762937], Bias: [-0.2195716]\n",
      "Loss: 3.3910605907440186, Weight: [3.5682423], Bias: [-0.19050251]\n",
      "Loss: 3.3008463382720947, Weight: [3.5603263], Bias: [-0.16192497]\n",
      "Loss: 3.213658571243286, Weight: [3.5525448], Bias: [-0.13383037]\n",
      "Loss: 3.129387378692627, Weight: [3.5448947], Bias: [-0.10621078]\n",
      "Loss: 3.0479471683502197, Weight: [3.5373738], Bias: [-0.07905811]\n",
      "Loss: 2.9692342281341553, Weight: [3.52998], Bias: [-0.05236446]\n",
      "Loss: 2.8931615352630615, Weight: [3.5227113], Bias: [-0.02612203]\n",
      "Loss: 2.8196380138397217, Weight: [3.5155654], Bias: [-0.00032322]\n",
      "Loss: 2.7485814094543457, Weight: [3.5085404], Bias: [0.02503947]\n",
      "Loss: 2.6799027919769287, Weight: [3.5016341], Bias: [0.04997339]\n",
      "Loss: 2.6135289669036865, Weight: [3.4948447], Bias: [0.07448582]\n",
      "Loss: 2.5493810176849365, Weight: [3.4881697], Bias: [0.09858382]\n",
      "Loss: 2.487381935119629, Weight: [3.481608], Bias: [0.12227452]\n",
      "Loss: 2.4274613857269287, Weight: [3.475157], Bias: [0.1455647]\n",
      "Loss: 2.369551420211792, Weight: [3.4688146], Bias: [0.16846108]\n",
      "Loss: 2.3135805130004883, Weight: [3.4625804], Bias: [0.19097061]\n",
      "Loss: 2.259488821029663, Weight: [3.4564507], Bias: [0.21309942]\n",
      "Loss: 2.2072062492370605, Weight: [3.4504251], Bias: [0.23485428]\n",
      "Loss: 2.1566786766052246, Weight: [3.4445014], Bias: [0.25624132]\n",
      "Loss: 2.1078476905822754, Weight: [3.4386775], Bias: [0.2772668]\n",
      "Loss: 2.0606517791748047, Weight: [3.4329522], Bias: [0.29793686]\n",
      "Loss: 2.0150363445281982, Weight: [3.4273238], Bias: [0.3182575]\n",
      "Loss: 1.9709526300430298, Weight: [3.4217904], Bias: [0.3382346]\n",
      "Loss: 1.9283424615859985, Weight: [3.4163506], Bias: [0.35787404]\n",
      "Loss: 1.8871644735336304, Weight: [3.4110029], Bias: [0.37718147]\n",
      "Loss: 1.8473671674728394, Weight: [3.4057453], Bias: [0.39616248]\n",
      "Loss: 1.8089028596878052, Weight: [3.4005768], Bias: [0.41482267]\n",
      "Loss: 1.7717286348342896, Weight: [3.3954954], Bias: [0.43316734]\n",
      "Loss: 1.7357993125915527, Weight: [3.3905003], Bias: [0.45120198]\n",
      "Loss: 1.7010751962661743, Weight: [3.3855894], Bias: [0.46893167]\n",
      "Loss: 1.6675145626068115, Weight: [3.3807616], Bias: [0.4863617]\n",
      "Loss: 1.6350821256637573, Weight: [3.3760152], Bias: [0.50349706]\n",
      "Loss: 1.603731632232666, Weight: [3.3713496], Bias: [0.5203428]\n",
      "Loss: 1.5734363794326782, Weight: [3.3667622], Bias: [0.5369037]\n",
      "Loss: 1.5441559553146362, Weight: [3.3622527], Bias: [0.5531847]\n",
      "Loss: 1.5158567428588867, Weight: [3.3578193], Bias: [0.56919044]\n",
      "Loss: 1.4885066747665405, Weight: [3.353461], Bias: [0.5849256]\n",
      "Loss: 1.4620715379714966, Weight: [3.3491764], Bias: [0.6003947]\n",
      "Loss: 1.436524510383606, Weight: [3.3449638], Bias: [0.6156023]\n",
      "Loss: 1.4118338823318481, Weight: [3.340823], Bias: [0.63055295]\n",
      "Loss: 1.3879693746566772, Weight: [3.336752], Bias: [0.6452508]\n",
      "Loss: 1.364906668663025, Weight: [3.3327496], Bias: [0.65970016]\n",
      "Loss: 1.3426158428192139, Weight: [3.328815], Bias: [0.67390525]\n",
      "Loss: 1.3210731744766235, Weight: [3.3249469], Bias: [0.68787026]\n",
      "Loss: 1.3002524375915527, Weight: [3.3211443], Bias: [0.7015992]\n",
      "Loss: 1.2801296710968018, Weight: [3.3174057], Bias: [0.71509594]\n",
      "Loss: 1.2606815099716187, Weight: [3.3137307], Bias: [0.72836465]\n",
      "Loss: 1.2418850660324097, Weight: [3.3101175], Bias: [0.74140894]\n",
      "Loss: 1.2237187623977661, Weight: [3.3065655], Bias: [0.7542328]\n",
      "Loss: 1.2061623334884644, Weight: [3.3030736], Bias: [0.7668399]\n",
      "Loss: 1.189193844795227, Weight: [3.2996407], Bias: [0.7792339]\n",
      "Loss: 1.1727938652038574, Weight: [3.2962658], Bias: [0.79141825]\n",
      "Loss: 1.1569435596466064, Weight: [3.292948], Bias: [0.8033967]\n",
      "Loss: 1.1416246891021729, Weight: [3.289686], Bias: [0.8151726]\n",
      "Loss: 1.126820683479309, Weight: [3.2864797], Bias: [0.8267496]\n",
      "Loss: 1.1125117540359497, Weight: [3.283327], Bias: [0.8381308]\n",
      "Loss: 1.0986826419830322, Weight: [3.280228], Bias: [0.8493195]\n",
      "Loss: 1.0853173732757568, Weight: [3.2771814], Bias: [0.8603192]\n",
      "Loss: 1.072399616241455, Weight: [3.2741861], Bias: [0.8711329]\n",
      "Loss: 1.0599159002304077, Weight: [3.2712414], Bias: [0.88176376]\n",
      "Loss: 1.0478501319885254, Weight: [3.2683468], Bias: [0.89221495]\n",
      "Loss: 1.0361894369125366, Weight: [3.2655008], Bias: [0.9024894]\n",
      "Loss: 1.0249176025390625, Weight: [3.2627032], Bias: [0.91259027]\n",
      "Loss: 1.014026403427124, Weight: [3.2599525], Bias: [0.9225203]\n",
      "Loss: 1.0034980773925781, Weight: [3.2572486], Bias: [0.9322825]\n",
      "Loss: 0.9933243989944458, Weight: [3.2545903], Bias: [0.94187963]\n",
      "Loss: 0.9834908843040466, Weight: [3.2519772], Bias: [0.9513146]\n",
      "Loss: 0.9739864468574524, Weight: [3.2494078], Bias: [0.96059]\n",
      "Loss: 0.9648022651672363, Weight: [3.246882], Bias: [0.9697086]\n",
      "Loss: 0.9559248089790344, Weight: [3.2443993], Bias: [0.97867316]\n",
      "Loss: 0.9473450779914856, Weight: [3.2419581], Bias: [0.98748606]\n",
      "Loss: 0.9390538334846497, Weight: [3.2395585], Bias: [0.99615]\n",
      "Loss: 0.9310396909713745, Weight: [3.237199], Bias: [1.0046675]\n",
      "Loss: 0.9232938885688782, Weight: [3.23488], Bias: [1.013041]\n",
      "Loss: 0.9158087968826294, Weight: [3.2325997], Bias: [1.0212729]\n",
      "Loss: 0.9085725545883179, Weight: [3.2303581], Bias: [1.0293657]\n",
      "Loss: 0.9015814065933228, Weight: [3.2281544], Bias: [1.0373217]\n",
      "Loss: 0.8948225975036621, Weight: [3.2259881], Bias: [1.0451432]\n",
      "Loss: 0.8882918953895569, Weight: [3.2238584], Bias: [1.0528325]\n",
      "Loss: 0.8819791674613953, Weight: [3.2217646], Bias: [1.0603918]\n",
      "Loss: 0.8758794069290161, Weight: [3.219706], Bias: [1.0678233]\n",
      "Loss: 0.8699826598167419, Weight: [3.2176824], Bias: [1.0751292]\n",
      "Loss: 0.8642839193344116, Weight: [3.215693], Bias: [1.0823115]\n",
      "Loss: 0.8587767481803894, Weight: [3.2137372], Bias: [1.0893724]\n",
      "Loss: 0.853454053401947, Weight: [3.2118146], Bias: [1.096314]\n",
      "Loss: 0.8483099341392517, Weight: [3.2099245], Bias: [1.1031382]\n",
      "Loss: 0.8433383703231812, Weight: [3.2080662], Bias: [1.1098471]\n",
      "Loss: 0.8385327458381653, Weight: [3.2062395], Bias: [1.1164426]\n",
      "Loss: 0.833888590335846, Weight: [3.2044435], Bias: [1.1229265]\n",
      "Loss: 0.8294004201889038, Weight: [3.2026777], Bias: [1.1293008]\n",
      "Loss: 0.8250623941421509, Weight: [3.2009418], Bias: [1.1355674]\n",
      "Loss: 0.8208692073822021, Weight: [3.1992357], Bias: [1.1417282]\n",
      "Loss: 0.8168175220489502, Weight: [3.197558], Bias: [1.1477846]\n",
      "Loss: 0.8129014372825623, Weight: [3.1959088], Bias: [1.1537387]\n",
      "Loss: 0.8091158270835876, Weight: [3.1942875], Bias: [1.1595923]\n",
      "Loss: 0.8054577708244324, Weight: [3.1926935], Bias: [1.1653467]\n",
      "Loss: 0.8019229769706726, Weight: [3.1911266], Bias: [1.171004]\n",
      "Loss: 0.7985059022903442, Weight: [3.1895862], Bias: [1.1765656]\n",
      "Loss: 0.7952046394348145, Weight: [3.1880717], Bias: [1.1820333]\n",
      "Loss: 0.7920132875442505, Weight: [3.1865828], Bias: [1.1874084]\n",
      "Loss: 0.7889281511306763, Weight: [3.1851192], Bias: [1.1926928]\n",
      "Loss: 0.7859472036361694, Weight: [3.18368], Bias: [1.1978877]\n",
      "Loss: 0.7830645442008972, Weight: [3.1822658], Bias: [1.202995]\n",
      "Loss: 0.7802809476852417, Weight: [3.1808748], Bias: [1.2080157]\n",
      "Loss: 0.7775896787643433, Weight: [3.1795077], Bias: [1.2129517]\n",
      "Loss: 0.77498859167099, Weight: [3.1781638], Bias: [1.2178042]\n",
      "Loss: 0.7724747061729431, Weight: [3.1768422], Bias: [1.2225746]\n",
      "Loss: 0.7700445652008057, Weight: [3.1755435], Bias: [1.2272645]\n",
      "Loss: 0.7676964402198792, Weight: [3.1742663], Bias: [1.2318751]\n",
      "Loss: 0.7654270529747009, Weight: [3.1730108], Bias: [1.2364076]\n",
      "Loss: 0.7632339000701904, Weight: [3.1717768], Bias: [1.2408637]\n",
      "Loss: 0.7611136436462402, Weight: [3.1705632], Bias: [1.2452443]\n",
      "Loss: 0.7590645551681519, Weight: [3.1693704], Bias: [1.2495508]\n",
      "Loss: 0.7570849061012268, Weight: [3.1681976], Bias: [1.2537847]\n",
      "Loss: 0.755171537399292, Weight: [3.1670449], Bias: [1.257947]\n",
      "Loss: 0.753321647644043, Weight: [3.1659114], Bias: [1.2620388]\n",
      "Loss: 0.7515338659286499, Weight: [3.164797], Bias: [1.2660615]\n",
      "Loss: 0.7498058080673218, Weight: [3.1637018], Bias: [1.2700163]\n",
      "Loss: 0.7481365203857422, Weight: [3.1626248], Bias: [1.2739041]\n",
      "Loss: 0.7465225458145142, Weight: [3.1615663], Bias: [1.2777262]\n",
      "Loss: 0.7449629902839661, Weight: [3.1605256], Bias: [1.2814837]\n",
      "Loss: 0.7434560656547546, Weight: [3.1595025], Bias: [1.2851776]\n",
      "Loss: 0.7419992685317993, Weight: [3.1584966], Bias: [1.2888091]\n",
      "Loss: 0.7405920624732971, Weight: [3.1575077], Bias: [1.2923791]\n",
      "Loss: 0.7392303943634033, Weight: [3.1565354], Bias: [1.2958889]\n",
      "Loss: 0.7379155158996582, Weight: [3.1555798], Bias: [1.2993394]\n",
      "Loss: 0.7366439700126648, Weight: [3.1546402], Bias: [1.3027315]\n",
      "Loss: 0.7354157567024231, Weight: [3.1537166], Bias: [1.3060663]\n",
      "Loss: 0.7342293858528137, Weight: [3.1528084], Bias: [1.3093446]\n",
      "Loss: 0.7330816388130188, Weight: [3.1519158], Bias: [1.3125677]\n",
      "Loss: 0.731972336769104, Weight: [3.151038], Bias: [1.3157362]\n",
      "Loss: 0.7309010028839111, Weight: [3.1501753], Bias: [1.3188512]\n",
      "Loss: 0.7298637628555298, Weight: [3.149327], Bias: [1.3219135]\n",
      "Loss: 0.7288628220558167, Weight: [3.1484933], Bias: [1.324924]\n",
      "Loss: 0.7278951406478882, Weight: [3.1476734], Bias: [1.3278836]\n",
      "Loss: 0.7269606590270996, Weight: [3.1468678], Bias: [1.3307933]\n",
      "Loss: 0.7260566353797913, Weight: [3.1460752], Bias: [1.3336536]\n",
      "Loss: 0.7251831293106079, Weight: [3.1452963], Bias: [1.3364656]\n",
      "Loss: 0.7243382334709167, Weight: [3.1445308], Bias: [1.3392302]\n",
      "Loss: 0.7235229015350342, Weight: [3.1437778], Bias: [1.3419479]\n",
      "Loss: 0.7227345705032349, Weight: [3.143038], Bias: [1.3446198]\n",
      "Loss: 0.7219724655151367, Weight: [3.1423101], Bias: [1.3472464]\n",
      "Loss: 0.7212358117103577, Weight: [3.1415951], Bias: [1.3498287]\n",
      "Loss: 0.7205238938331604, Weight: [3.1408918], Bias: [1.3523673]\n",
      "Loss: 0.7198360562324524, Weight: [3.1402006], Bias: [1.354863]\n",
      "Loss: 0.7191706299781799, Weight: [3.139521], Bias: [1.3573165]\n",
      "Loss: 0.7185279130935669, Weight: [3.138853], Bias: [1.3597286]\n",
      "Loss: 0.7179067730903625, Weight: [3.1381962], Bias: [1.3620998]\n",
      "Loss: 0.7173064351081848, Weight: [3.1375504], Bias: [1.3644309]\n",
      "Loss: 0.7167262434959412, Weight: [3.1369157], Bias: [1.3667227]\n",
      "Loss: 0.7161652445793152, Weight: [3.1362917], Bias: [1.3689758]\n",
      "Loss: 0.7156234979629517, Weight: [3.135678], Bias: [1.3711907]\n",
      "Loss: 0.7150996923446655, Weight: [3.1350749], Bias: [1.3733681]\n",
      "Loss: 0.7145938873291016, Weight: [3.1344821], Bias: [1.3755089]\n",
      "Loss: 0.7141042351722717, Weight: [3.133899], Bias: [1.3776133]\n",
      "Loss: 0.7136320471763611, Weight: [3.133326], Bias: [1.3796823]\n",
      "Loss: 0.7131748795509338, Weight: [3.1327627], Bias: [1.3817163]\n",
      "Loss: 0.7127331495285034, Weight: [3.1322088], Bias: [1.3837157]\n",
      "Loss: 0.7123062610626221, Weight: [3.1316645], Bias: [1.3856815]\n",
      "Loss: 0.7118940949440002, Weight: [3.131129], Bias: [1.387614]\n",
      "Loss: 0.711494505405426, Weight: [3.1306028], Bias: [1.389514]\n",
      "Loss: 0.7111095786094666, Weight: [3.1300855], Bias: [1.3913817]\n",
      "Loss: 0.7107366919517517, Weight: [3.129577], Bias: [1.3932179]\n",
      "Loss: 0.7103772163391113, Weight: [3.129077], Bias: [1.3950231]\n",
      "Loss: 0.7100291848182678, Weight: [3.1285853], Bias: [1.3967977]\n",
      "Loss: 0.7096935510635376, Weight: [3.1281023], Bias: [1.3985423]\n",
      "Loss: 0.709368109703064, Weight: [3.1276271], Bias: [1.4002573]\n",
      "Loss: 0.7090546488761902, Weight: [3.12716], Bias: [1.4019434]\n",
      "Loss: 0.7087506651878357, Weight: [3.1267009], Bias: [1.403601]\n",
      "Loss: 0.7084577083587646, Weight: [3.1262496], Bias: [1.4052306]\n",
      "Loss: 0.708173394203186, Weight: [3.1258059], Bias: [1.4068327]\n",
      "Loss: 0.7078996896743774, Weight: [3.1253695], Bias: [1.4084077]\n",
      "Loss: 0.7076354026794434, Weight: [3.1249409], Bias: [1.4099561]\n",
      "Loss: 0.7073789238929749, Weight: [3.124519], Bias: [1.4114783]\n",
      "Loss: 0.7071321606636047, Weight: [3.1241045], Bias: [1.4129747]\n",
      "Loss: 0.706892728805542, Weight: [3.1236973], Bias: [1.4144459]\n",
      "Loss: 0.7066613435745239, Weight: [3.1232965], Bias: [1.4158921]\n",
      "Loss: 0.7064381241798401, Weight: [3.1229026], Bias: [1.4173139]\n",
      "Loss: 0.7062228918075562, Weight: [3.1225154], Bias: [1.4187118]\n",
      "Loss: 0.7060136795043945, Weight: [3.122135], Bias: [1.4200859]\n",
      "Loss: 0.7058120965957642, Weight: [3.1217606], Bias: [1.4214368]\n",
      "Loss: 0.7056169509887695, Weight: [3.121393], Bias: [1.4227649]\n",
      "Loss: 0.7054288387298584, Weight: [3.1210313], Bias: [1.4240705]\n",
      "Loss: 0.7052467465400696, Weight: [3.1206758], Bias: [1.425354]\n",
      "Loss: 0.7050708532333374, Weight: [3.1203263], Bias: [1.4266158]\n",
      "Loss: 0.7049007415771484, Weight: [3.1199825], Bias: [1.4278563]\n",
      "Loss: 0.7047370672225952, Weight: [3.1196449], Bias: [1.429076]\n",
      "Loss: 0.7045775651931763, Weight: [3.1193128], Bias: [1.430275]\n",
      "Loss: 0.704424262046814, Weight: [3.1189864], Bias: [1.4314536]\n",
      "Loss: 0.7042762041091919, Weight: [3.1186655], Bias: [1.4326123]\n",
      "Loss: 0.7041330933570862, Weight: [3.1183498], Bias: [1.4337515]\n",
      "Loss: 0.703994870185852, Weight: [3.1180396], Bias: [1.4348714]\n",
      "Loss: 0.7038609981536865, Weight: [3.1177344], Bias: [1.4359725]\n",
      "Loss: 0.7037307620048523, Weight: [3.117435], Bias: [1.4370549]\n",
      "Loss: 0.7036057114601135, Weight: [3.11714], Bias: [1.4381189]\n",
      "Loss: 0.7034850716590881, Weight: [3.1168504], Bias: [1.439165]\n",
      "Loss: 0.7033680081367493, Weight: [3.1165655], Bias: [1.4401934]\n",
      "Loss: 0.703255832195282, Weight: [3.1162853], Bias: [1.4412044]\n",
      "Loss: 0.7031463384628296, Weight: [3.1160102], Bias: [1.4421984]\n",
      "Loss: 0.703040599822998, Weight: [3.1157393], Bias: [1.4431756]\n",
      "Loss: 0.7029384970664978, Weight: [3.1154733], Bias: [1.4441361]\n",
      "Loss: 0.7028402090072632, Weight: [3.115212], Bias: [1.4450805]\n",
      "Loss: 0.7027451395988464, Weight: [3.1149547], Bias: [1.4460089]\n",
      "Loss: 0.7026534676551819, Weight: [3.114702], Bias: [1.4469216]\n",
      "Loss: 0.7025646567344666, Weight: [3.1144533], Bias: [1.4478189]\n",
      "Loss: 0.7024780511856079, Weight: [3.114209], Bias: [1.448701]\n",
      "Loss: 0.702394962310791, Weight: [3.1139686], Bias: [1.4495683]\n",
      "Loss: 0.702315092086792, Weight: [3.1137326], Bias: [1.4504209]\n",
      "Loss: 0.7022368907928467, Weight: [3.1135006], Bias: [1.451259]\n",
      "Loss: 0.7021623253822327, Weight: [3.1132722], Bias: [1.452083]\n",
      "Loss: 0.7020896673202515, Weight: [3.1130478], Bias: [1.452893]\n",
      "Loss: 0.7020189166069031, Weight: [3.1128273], Bias: [1.4536893]\n",
      "Loss: 0.701951801776886, Weight: [3.1126103], Bias: [1.4544722]\n",
      "Loss: 0.7018858790397644, Weight: [3.1123974], Bias: [1.4552419]\n",
      "Loss: 0.7018226385116577, Weight: [3.1121876], Bias: [1.4559985]\n",
      "Loss: 0.701761782169342, Weight: [3.1119816], Bias: [1.4567424]\n",
      "Loss: 0.7017027139663696, Weight: [3.111779], Bias: [1.4574736]\n",
      "Loss: 0.7016461491584778, Weight: [3.11158], Bias: [1.4581926]\n",
      "Loss: 0.7015907764434814, Weight: [3.1113842], Bias: [1.4588994]\n",
      "Loss: 0.7015376687049866, Weight: [3.1111917], Bias: [1.4595942]\n",
      "Loss: 0.7014859318733215, Weight: [3.1110027], Bias: [1.4602773]\n",
      "Loss: 0.7014356851577759, Weight: [3.1108165], Bias: [1.4609488]\n",
      "Loss: 0.7013880610466003, Weight: [3.1106336], Bias: [1.461609]\n",
      "Loss: 0.7013412117958069, Weight: [3.1104538], Bias: [1.462258]\n",
      "Loss: 0.7012956738471985, Weight: [3.1102772], Bias: [1.462896]\n",
      "Loss: 0.7012526392936707, Weight: [3.1101034], Bias: [1.4635233]\n",
      "Loss: 0.7012115120887756, Weight: [3.1099327], Bias: [1.4641399]\n",
      "Loss: 0.7011702656745911, Weight: [3.1097648], Bias: [1.4647461]\n",
      "Loss: 0.701130747795105, Weight: [3.1095996], Bias: [1.465342]\n",
      "Loss: 0.7010936737060547, Weight: [3.1094375], Bias: [1.465928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.701056718826294, Weight: [3.109278], Bias: [1.466504]\n",
      "Loss: 0.701021134853363, Weight: [3.109121], Bias: [1.4670702]\n",
      "Loss: 0.7009865045547485, Weight: [3.1089668], Bias: [1.4676268]\n",
      "Loss: 0.7009537220001221, Weight: [3.1088154], Bias: [1.4681741]\n",
      "Loss: 0.7009214758872986, Weight: [3.1086662], Bias: [1.4687121]\n",
      "Loss: 0.7008914947509766, Weight: [3.1085198], Bias: [1.469241]\n",
      "Loss: 0.7008610963821411, Weight: [3.1083758], Bias: [1.469761]\n",
      "Loss: 0.700831949710846, Weight: [3.1082342], Bias: [1.4702722]\n",
      "Loss: 0.7008041739463806, Weight: [3.108095], Bias: [1.4707747]\n",
      "Loss: 0.7007772326469421, Weight: [3.107958], Bias: [1.4712687]\n",
      "Loss: 0.7007513046264648, Weight: [3.1078236], Bias: [1.4717543]\n",
      "Loss: 0.7007264494895935, Weight: [3.1076913], Bias: [1.4722319]\n",
      "Loss: 0.7007015943527222, Weight: [3.1075613], Bias: [1.4727013]\n",
      "Loss: 0.7006785273551941, Weight: [3.1074336], Bias: [1.4731628]\n",
      "Loss: 0.7006551623344421, Weight: [3.107308], Bias: [1.4736165]\n",
      "Loss: 0.7006332278251648, Weight: [3.1071844], Bias: [1.4740624]\n",
      "Loss: 0.7006122469902039, Weight: [3.1070628], Bias: [1.4745009]\n",
      "Loss: 0.7005915641784668, Weight: [3.1069436], Bias: [1.474932]\n",
      "Loss: 0.7005713582038879, Weight: [3.106826], Bias: [1.4753557]\n",
      "Loss: 0.7005521059036255, Weight: [3.1067107], Bias: [1.4757724]\n",
      "Loss: 0.7005342245101929, Weight: [3.1065974], Bias: [1.476182]\n",
      "Loss: 0.7005165219306946, Weight: [3.1064856], Bias: [1.4765846]\n",
      "Loss: 0.7004987597465515, Weight: [3.1063762], Bias: [1.4769804]\n",
      "Loss: 0.7004820704460144, Weight: [3.1062684], Bias: [1.4773695]\n",
      "Loss: 0.7004655003547668, Weight: [3.1061623], Bias: [1.4777521]\n",
      "Loss: 0.7004508376121521, Weight: [3.1060581], Bias: [1.4781282]\n",
      "Loss: 0.7004353404045105, Weight: [3.1059556], Bias: [1.4784979]\n",
      "Loss: 0.7004208564758301, Weight: [3.105855], Bias: [1.4788615]\n",
      "Loss: 0.7004063725471497, Weight: [3.105756], Bias: [1.4792188]\n",
      "Loss: 0.7003933787345886, Weight: [3.1056588], Bias: [1.4795702]\n",
      "Loss: 0.7003793120384216, Weight: [3.105563], Bias: [1.4799155]\n",
      "Loss: 0.7003674507141113, Weight: [3.105469], Bias: [1.480255]\n",
      "Loss: 0.7003549337387085, Weight: [3.1053767], Bias: [1.4805888]\n",
      "Loss: 0.700343132019043, Weight: [3.1052856], Bias: [1.4809169]\n",
      "Loss: 0.700331449508667, Weight: [3.1051962], Bias: [1.4812394]\n",
      "Loss: 0.7003200650215149, Weight: [3.1051085], Bias: [1.4815567]\n",
      "Loss: 0.7003090381622314, Weight: [3.1050222], Bias: [1.4818684]\n",
      "Loss: 0.7002987861633301, Weight: [3.1049373], Bias: [1.4821749]\n",
      "Loss: 0.7002891302108765, Weight: [3.1048536], Bias: [1.4824761]\n",
      "Loss: 0.7002794742584229, Weight: [3.1047719], Bias: [1.4827724]\n",
      "Loss: 0.7002696990966797, Weight: [3.104691], Bias: [1.4830636]\n",
      "Loss: 0.7002608776092529, Weight: [3.1046119], Bias: [1.4833499]\n",
      "Loss: 0.7002525329589844, Weight: [3.1045337], Bias: [1.4836314]\n",
      "Loss: 0.7002436518669128, Weight: [3.1044574], Bias: [1.4839082]\n",
      "Loss: 0.7002362012863159, Weight: [3.1043818], Bias: [1.4841802]\n",
      "Loss: 0.7002271413803101, Weight: [3.104308], Bias: [1.4844477]\n",
      "Loss: 0.7002207040786743, Weight: [3.104235], Bias: [1.4847106]\n",
      "Loss: 0.700212836265564, Weight: [3.1041634], Bias: [1.484969]\n",
      "Loss: 0.7002056241035461, Weight: [3.104093], Bias: [1.485223]\n",
      "Loss: 0.7001985907554626, Weight: [3.1040237], Bias: [1.4854728]\n",
      "Loss: 0.7001919746398926, Weight: [3.1039557], Bias: [1.4857184]\n",
      "Loss: 0.7001855373382568, Weight: [3.103889], Bias: [1.4859598]\n",
      "Loss: 0.7001800537109375, Weight: [3.1038232], Bias: [1.4861971]\n",
      "Loss: 0.7001728415489197, Weight: [3.1037586], Bias: [1.4864304]\n",
      "Loss: 0.7001681327819824, Weight: [3.103695], Bias: [1.4866598]\n",
      "Loss: 0.7001619338989258, Weight: [3.1036325], Bias: [1.4868853]\n",
      "Loss: 0.7001559138298035, Weight: [3.1035712], Bias: [1.487107]\n",
      "Loss: 0.7001506686210632, Weight: [3.1035106], Bias: [1.487325]\n",
      "Loss: 0.7001467943191528, Weight: [3.1034515], Bias: [1.4875393]\n",
      "Loss: 0.700141191482544, Weight: [3.103393], Bias: [1.4877499]\n",
      "Loss: 0.7001367211341858, Weight: [3.1033359], Bias: [1.487957]\n",
      "Loss: 0.7001321911811829, Weight: [3.1032794], Bias: [1.4881605]\n",
      "Loss: 0.700127899646759, Weight: [3.103224], Bias: [1.4883606]\n",
      "Loss: 0.7001237273216248, Weight: [3.1031694], Bias: [1.4885573]\n",
      "Loss: 0.7001192569732666, Weight: [3.1031158], Bias: [1.4887508]\n",
      "Loss: 0.7001157999038696, Weight: [3.1030633], Bias: [1.4889411]\n",
      "Loss: 0.7001116275787354, Weight: [3.1030114], Bias: [1.489128]\n",
      "Loss: 0.7001076936721802, Weight: [3.1029603], Bias: [1.4893118]\n",
      "Loss: 0.7001035809516907, Weight: [3.1029103], Bias: [1.4894925]\n",
      "Loss: 0.7001001834869385, Weight: [3.1028612], Bias: [1.4896702]\n",
      "Loss: 0.7000976204872131, Weight: [3.1028128], Bias: [1.4898448]\n",
      "Loss: 0.7000939249992371, Weight: [3.1027653], Bias: [1.4900165]\n",
      "Loss: 0.7000903487205505, Weight: [3.1027186], Bias: [1.4901853]\n",
      "Loss: 0.7000871300697327, Weight: [3.1026723], Bias: [1.4903511]\n",
      "Loss: 0.7000852823257446, Weight: [3.1026275], Bias: [1.4905143]\n",
      "Loss: 0.7000821232795715, Weight: [3.102583], Bias: [1.4906746]\n",
      "Loss: 0.7000787854194641, Weight: [3.1025393], Bias: [1.4908322]\n",
      "Loss: 0.7000766396522522, Weight: [3.1024964], Bias: [1.4909872]\n",
      "Loss: 0.7000742554664612, Weight: [3.1024542], Bias: [1.4911395]\n",
      "Loss: 0.700071394443512, Weight: [3.1024127], Bias: [1.4912894]\n",
      "Loss: 0.7000688910484314, Weight: [3.102372], Bias: [1.4914366]\n",
      "Loss: 0.700066328048706, Weight: [3.1023319], Bias: [1.4915813]\n",
      "Loss: 0.7000650763511658, Weight: [3.1022925], Bias: [1.4917237]\n",
      "Loss: 0.7000622153282166, Weight: [3.1022534], Bias: [1.4918635]\n",
      "Loss: 0.7000595927238464, Weight: [3.1022158], Bias: [1.4920012]\n",
      "Loss: 0.7000579833984375, Weight: [3.102178], Bias: [1.4921364]\n",
      "Loss: 0.700056791305542, Weight: [3.1021414], Bias: [1.4922693]\n",
      "Loss: 0.700054407119751, Weight: [3.1021051], Bias: [1.4923999]\n",
      "Loss: 0.7000526189804077, Weight: [3.1020694], Bias: [1.4925283]\n",
      "Loss: 0.7000513076782227, Weight: [3.1020346], Bias: [1.4926547]\n",
      "Loss: 0.700049102306366, Weight: [3.1020002], Bias: [1.4927789]\n",
      "Loss: 0.7000474333763123, Weight: [3.1019661], Bias: [1.492901]\n",
      "Loss: 0.7000455856323242, Weight: [3.1019332], Bias: [1.493021]\n",
      "Loss: 0.7000442147254944, Weight: [3.1019003], Bias: [1.4931389]\n",
      "Loss: 0.7000422477722168, Weight: [3.1018684], Bias: [1.4932549]\n",
      "Loss: 0.7000420093536377, Weight: [3.1018367], Bias: [1.4933689]\n",
      "Loss: 0.7000405788421631, Weight: [3.1018057], Bias: [1.4934809]\n",
      "Loss: 0.7000386714935303, Weight: [3.1017752], Bias: [1.4935911]\n",
      "Loss: 0.7000373005867004, Weight: [3.1017451], Bias: [1.4936994]\n",
      "Loss: 0.7000367045402527, Weight: [3.1017156], Bias: [1.493806]\n",
      "Loss: 0.7000347375869751, Weight: [3.1016867], Bias: [1.4939107]\n",
      "Loss: 0.7000338435173035, Weight: [3.101658], Bias: [1.4940135]\n",
      "Loss: 0.7000320553779602, Weight: [3.10163], Bias: [1.4941148]\n",
      "Loss: 0.7000318169593811, Weight: [3.1016026], Bias: [1.4942143]\n",
      "Loss: 0.7000304460525513, Weight: [3.1015754], Bias: [1.494312]\n",
      "Loss: 0.7000300288200378, Weight: [3.1015487], Bias: [1.4944082]\n",
      "Loss: 0.7000283598899841, Weight: [3.1015227], Bias: [1.4945028]\n",
      "Loss: 0.7000269293785095, Weight: [3.101497], Bias: [1.4945958]\n",
      "Loss: 0.7000270485877991, Weight: [3.1014714], Bias: [1.4946871]\n",
      "Loss: 0.7000254988670349, Weight: [3.1014466], Bias: [1.494777]\n",
      "Loss: 0.7000243067741394, Weight: [3.1014223], Bias: [1.4948653]\n",
      "Loss: 0.7000240087509155, Weight: [3.1013982], Bias: [1.4949521]\n",
      "Loss: 0.7000234723091125, Weight: [3.1013746], Bias: [1.4950374]\n",
      "Loss: 0.7000226974487305, Weight: [3.1013513], Bias: [1.4951214]\n",
      "Loss: 0.7000217437744141, Weight: [3.1013286], Bias: [1.4952039]\n",
      "Loss: 0.7000211477279663, Weight: [3.101306], Bias: [1.4952849]\n",
      "Loss: 0.7000201940536499, Weight: [3.101284], Bias: [1.4953647]\n",
      "Loss: 0.7000191807746887, Weight: [3.101262], Bias: [1.495443]\n",
      "Loss: 0.7000186443328857, Weight: [3.1012409], Bias: [1.4955201]\n",
      "Loss: 0.7000187039375305, Weight: [3.10122], Bias: [1.4955958]\n",
      "Loss: 0.7000179290771484, Weight: [3.1011992], Bias: [1.4956702]\n",
      "Loss: 0.7000170946121216, Weight: [3.1011791], Bias: [1.4957434]\n",
      "Loss: 0.70001620054245, Weight: [3.101159], Bias: [1.4958153]\n",
      "Loss: 0.7000159025192261, Weight: [3.1011395], Bias: [1.4958861]\n",
      "Loss: 0.7000148892402649, Weight: [3.1011202], Bias: [1.4959556]\n",
      "Loss: 0.700014591217041, Weight: [3.1011014], Bias: [1.496024]\n",
      "Loss: 0.7000141143798828, Weight: [3.1010828], Bias: [1.4960912]\n",
      "Loss: 0.7000142335891724, Weight: [3.1010644], Bias: [1.4961573]\n",
      "Loss: 0.7000131011009216, Weight: [3.1010463], Bias: [1.4962223]\n",
      "Loss: 0.7000125646591187, Weight: [3.1010287], Bias: [1.4962862]\n",
      "Loss: 0.7000119686126709, Weight: [3.1010113], Bias: [1.496349]\n",
      "Loss: 0.7000118494033813, Weight: [3.100994], Bias: [1.4964107]\n",
      "Loss: 0.7000120282173157, Weight: [3.1009774], Bias: [1.4964714]\n",
      "Loss: 0.700011134147644, Weight: [3.100961], Bias: [1.496531]\n",
      "Loss: 0.7000107765197754, Weight: [3.1009448], Bias: [1.4965897]\n",
      "Loss: 0.7000106573104858, Weight: [3.1009288], Bias: [1.4966472]\n",
      "Loss: 0.7000107169151306, Weight: [3.100913], Bias: [1.4967039]\n",
      "Loss: 0.7000098824501038, Weight: [3.1008976], Bias: [1.4967595]\n",
      "Loss: 0.7000094056129456, Weight: [3.1008823], Bias: [1.4968144]\n",
      "Loss: 0.7000088095664978, Weight: [3.1008673], Bias: [1.4968683]\n",
      "Loss: 0.7000089287757874, Weight: [3.1008527], Bias: [1.4969212]\n",
      "Loss: 0.7000082731246948, Weight: [3.1008384], Bias: [1.4969733]\n",
      "Loss: 0.7000089883804321, Weight: [3.100824], Bias: [1.4970244]\n",
      "Loss: 0.7000083923339844, Weight: [3.1008103], Bias: [1.4970747]\n",
      "Loss: 0.7000072598457336, Weight: [3.1007965], Bias: [1.4971242]\n",
      "Loss: 0.700007975101471, Weight: [3.100783], Bias: [1.4971728]\n",
      "Loss: 0.7000074982643127, Weight: [3.1007698], Bias: [1.4972206]\n",
      "Loss: 0.7000066041946411, Weight: [3.1007566], Bias: [1.4972676]\n",
      "Loss: 0.7000068426132202, Weight: [3.100744], Bias: [1.4973139]\n",
      "Loss: 0.7000071406364441, Weight: [3.1007316], Bias: [1.4973593]\n",
      "Loss: 0.7000062465667725, Weight: [3.100719], Bias: [1.4974039]\n",
      "Loss: 0.7000067234039307, Weight: [3.1007068], Bias: [1.4974477]\n",
      "Loss: 0.7000055313110352, Weight: [3.100695], Bias: [1.4974909]\n",
      "Loss: 0.700005829334259, Weight: [3.1006832], Bias: [1.4975333]\n",
      "Loss: 0.700005292892456, Weight: [3.1006715], Bias: [1.497575]\n",
      "Loss: 0.7000060081481934, Weight: [3.1006603], Bias: [1.497616]\n",
      "Loss: 0.7000051736831665, Weight: [3.100649], Bias: [1.4976563]\n",
      "Loss: 0.7000044584274292, Weight: [3.1006382], Bias: [1.4976959]\n",
      "Loss: 0.7000046968460083, Weight: [3.1006274], Bias: [1.4977349]\n",
      "Loss: 0.7000049352645874, Weight: [3.100617], Bias: [1.4977732]\n",
      "Loss: 0.7000042796134949, Weight: [3.1006062], Bias: [1.4978107]\n",
      "Loss: 0.7000047564506531, Weight: [3.1005962], Bias: [1.4978478]\n",
      "Loss: 0.7000048160552979, Weight: [3.100586], Bias: [1.4978842]\n",
      "Loss: 0.7000043988227844, Weight: [3.1005762], Bias: [1.4979199]\n",
      "Loss: 0.7000042796134949, Weight: [3.1005664], Bias: [1.4979551]\n",
      "Loss: 0.7000043988227844, Weight: [3.1005569], Bias: [1.4979897]\n",
      "Loss: 0.7000039219856262, Weight: [3.1005473], Bias: [1.4980236]\n",
      "Loss: 0.700003445148468, Weight: [3.100538], Bias: [1.498057]\n",
      "Loss: 0.7000030279159546, Weight: [3.100529], Bias: [1.4980899]\n",
      "Loss: 0.7000030279159546, Weight: [3.1005201], Bias: [1.4981222]\n",
      "Loss: 0.7000032663345337, Weight: [3.1005113], Bias: [1.4981539]\n",
      "Loss: 0.7000036239624023, Weight: [3.1005027], Bias: [1.4981852]\n",
      "Loss: 0.700002908706665, Weight: [3.1004941], Bias: [1.4982158]\n",
      "Loss: 0.7000028491020203, Weight: [3.1004858], Bias: [1.498246]\n",
      "Loss: 0.7000027894973755, Weight: [3.1004775], Bias: [1.4982756]\n",
      "Loss: 0.7000027894973755, Weight: [3.1004696], Bias: [1.4983048]\n",
      "Loss: 0.700002908706665, Weight: [3.1004617], Bias: [1.4983335]\n",
      "Loss: 0.7000025510787964, Weight: [3.1004536], Bias: [1.4983616]\n",
      "Loss: 0.7000025510787964, Weight: [3.1004462], Bias: [1.4983894]\n",
      "Loss: 0.7000024914741516, Weight: [3.1004386], Bias: [1.4984165]\n",
      "Loss: 0.7000021934509277, Weight: [3.100431], Bias: [1.4984432]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(500):\n",
    "        _, w_value, b_value, loss_value = sess.run([training_op, W, B, Loss], feed_dict={X: X_train, Y_: Y_train})\n",
    "        print(\"Loss: {}, Weight: {}, Bias: {}\".format(loss_value, w_value, b_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
